{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1717501a",
   "metadata": {},
   "source": [
    "# SpaceX Falcon 9 First Stage Landing Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b35595",
   "metadata": {},
   "source": [
    "## Lab 4: EDA with SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a91c6",
   "metadata": {},
   "source": [
    "### Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889454c2",
   "metadata": {},
   "source": [
    "Using this Python notebook you will:\n",
    "\n",
    "* Understand the SpaceX dataset\n",
    "* Load the dataset into the corresponding table in Db2 database\n",
    "* Execute SQL queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf1d8fe",
   "metadata": {},
   "source": [
    "### Overview of the dataset\n",
    "\n",
    "SpaceX has gained worldwide attention for a series of historic milestones.\n",
    "\n",
    "It is the only private company ever to return a spacecraft from low-earth orbit, which it first accomplished in December 2010.\n",
    "SpaceX advertises Falcon 9 rocket launches on its website with a cost of 62 million dollars wheras other providers cost upward of 165 million dollars each, much of the savings is because Space X can reuse the first stage.\n",
    "\n",
    "Therefore if we can determine if the first stage will land, we can determine the cost of a launch.\n",
    "\n",
    "This information can be used if an alternate company wants to bid against SpaceX for a rocket launch.\n",
    "\n",
    "This dataset includes a record for each payload carried during a SpaceX mission into outer space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c07cf6",
   "metadata": {},
   "source": [
    "### Download the datasets\n",
    "\n",
    "This assignment requires you to load the spacex dataset.\n",
    "\n",
    "In many cases the dataset to be analyzed is available as a .CSV (comma separated values) file, perhaps on the internet. Click on the link below to download and save the dataset (.CSV file):\n",
    "\n",
    "<a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01\" target=\"_blank\">Spacex DataSet</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b662ca",
   "metadata": {},
   "source": [
    "### Store the dataset in database table\n",
    "\n",
    "**it is highly recommended to manually load the table using the database console LOAD tool in DB2**.\n",
    "\n",
    "<img src = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/spacexload.png\">\n",
    "\n",
    "Now open the Db2 console, open the LOAD tool, Select / Drag the .CSV file for the  dataset, Next create a New Table, and then follow the steps on-screen instructions to load the data. Name the new table as follows:\n",
    "\n",
    "**SPACEXDATASET**\n",
    "\n",
    "**Follow these steps while using old DB2 UI which is having Open Console Screen**\n",
    "\n",
    "**Note:While loading Spacex dataset, ensure that detect datatypes is disabled. Later click on the pencil icon(edit option).**\n",
    "\n",
    "1.  Change the Date Format by manually typing DD-MM-YYYY and timestamp format as DD-MM-YYYY HH\\:MM:SS\n",
    "\n",
    "2.  Change the PAYLOAD_MASS\\_\\_KG\\_  datatype  to INTEGER.\n",
    "\n",
    "<img src = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/spacexload2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b126c6f",
   "metadata": {},
   "source": [
    "**Changes to be considered when having DB2 instance with the new UI having Go to UI screen**\n",
    "\n",
    "*   Refer to this insruction in this <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Sign%20up%20for%20IBM%20Cloud%20-%20Create%20Db2%20service%20instance%20-%20Get%20started%20with%20the%20Db2%20console/instructional-labs.md.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01\">link</a> for viewing  the new  Go to UI screen.\n",
    "\n",
    "*   Later click on **Data link(below SQL)**  in the Go to UI screen  and click on **Load Data** tab.\n",
    "\n",
    "*   Later browse for the downloaded spacex file.\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/browsefile.png\" width=\"800\"/>\n",
    "\n",
    "*   Once done select the schema andload the file.\n",
    "\n",
    " <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/spacexload3.png\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9f2ce",
   "metadata": {},
   "source": [
    "For this exercise, it was difficult to access IBM's Db2 t ohigh demand. To complete this exercise, we would make yuse of the postgre SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce53a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (2.9.5)\n",
      "Project libraries has been successfully installed!\n"
     ]
    }
   ],
   "source": [
    "# Install for the connection to postgres database (local)\n",
    "!pip install psycopg2\n",
    "\n",
    "import csv\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# Install fro the connection to the database using Db2 (cloud)\n",
    "#!pip install sqlachemy==1.3.9\n",
    "#!pip install ibm_db_sa\n",
    "#!pip install ipython-sql\n",
    "print('Project libraries has been successfully installed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f82f7",
   "metadata": {},
   "source": [
    "### Connect to the database using DB2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d52043",
   "metadata": {},
   "source": [
    "Load the SQL extension and establish a connection with the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c8515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy==1.3.9 in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (1.3.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy==1.3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c10668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-sql in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: sqlalchemy>=0.6.7 in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython-sql) (1.3.9)\n",
      "Requirement already satisfied: ipython>=1.0 in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython-sql) (7.29.0)\n",
      "Requirement already satisfied: prettytable<1 in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython-sql) (0.7.2)\n",
      "Requirement already satisfied: sqlparse in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython-sql) (0.4.3)\n",
      "Requirement already satisfied: ipython-genutils>=0.1.0 in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython-sql) (1.16.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (0.18.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (3.0.20)\n",
      "Requirement already satisfied: decorator in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (58.0.4)\n",
      "Requirement already satisfied: pygments in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (2.10.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (0.4.4)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (0.1.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (5.1.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=1.0->ipython-sql) (0.8.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\mhdkh\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql) (0.2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipython-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caca9791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8f407c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, sqlite3\n",
    "\n",
    "con = sqlite3.connect(\"my_data1.db\")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d1cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas==1.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33805852",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql sqlite:///my_data1.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25df5707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhdkh\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2605: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  sql.to_sql(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv\")\n",
    "df.to_sql(\"SPACEXTBL\", con, if_exists='replace', index=False,method=\"multi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee7c92",
   "metadata": {},
   "source": [
    "### Connect to the database using PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21268c63",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "connection to server at \"localhost\" (::1), port 5432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16052/3123507625.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# create connection to postgreSQL database\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m conn = psycopg2.connect(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mhost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'localhost'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdatabase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'postgres'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0muser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'postgres'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\psycopg2\\__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[0mdsn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_dsn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m     \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection_factory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconnection_factory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwasync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcursor_factory\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcursor_factory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: connection to server at \"localhost\" (::1), port 5432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\n"
     ]
    }
   ],
   "source": [
    "# create connection to postgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    host = 'localhost',\n",
    "    database = 'postgres', \n",
    "    user = 'postgres', \n",
    "    password = 'chuksoo',  \n",
    "    port = '5432')\n",
    "print('Connection to database is successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81cc99c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16052/3167241531.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# function to create pandas dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_pandas_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'conn' is not defined"
     ]
    }
   ],
   "source": [
    "# function to read from database\n",
    "def read(conn, read_):\n",
    "    print('Read')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(read_)\n",
    "    for row in cursor:\n",
    "        print(f'row = {row}')\n",
    "    print()\n",
    "    \n",
    "# function to create in postgre database     \n",
    "def create(conn, create_):\n",
    "    cursor = conn.cursor() # create cursor object\n",
    "    cursor.execute(create_) # execute query\n",
    "    conn.commit() # commit query to database\n",
    "    print('Table have been created successfull!!!')\n",
    "    #read(conn)\n",
    "    \n",
    "# function to insert in postgre database     \n",
    "def insert(conn, insert_):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(insert_)\n",
    "    conn.commit()\n",
    "    print('Records have been successfully inserted!!!')\n",
    "    #read(conn)\n",
    "    \n",
    "# function to update table\n",
    "def update(conn, update_):\n",
    "    print('Update')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(update_)\n",
    "    conn.commit()\n",
    "    #read(conn)\n",
    "    \n",
    "# function to delete in postgre database\n",
    "def delete(conn, delete_):\n",
    "    print('Delete')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(delete_)\n",
    "    conn.commit()\n",
    "    #read(conn)\n",
    "    \n",
    "# close the cursor and connection to the server \n",
    "def close():\n",
    "    cursor.close()\n",
    "    conn.close()   \n",
    "    \n",
    "# function to create pandas dataframe\n",
    "def create_pandas_df(sql_query, database=conn):\n",
    "    table = pd.read_sql_query(sql_query, database)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e6936f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
